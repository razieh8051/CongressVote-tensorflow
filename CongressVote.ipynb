{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 layered NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inputs, weights, biases):\n",
    "    #Create 2-layered NN\n",
    "    input_layer= tf.matmul(inputs,weights['input'])\n",
    "    # Hidden layer 1 (relu activation)\n",
    "    hidden_layer1= tf.nn.relu(input_layer + biases['input'])\n",
    "    #  Hidden layer 2 (relu activation)\n",
    "    hidden_layer2= tf.nn.relu(tf.matmul(hidden_layer1,weights['hidden1'])+biases['hidden1'])\n",
    "    # Output layer (linear activation)\n",
    "    output_layer= tf.matmul(hidden_layer2, weights['hidden2']) + biases['hidden2']\n",
    "\n",
    "    return output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Column is the label and others are the features\n",
    "COLUMNS = ['className','handicapped-infants','water-project-cost-sharing','adoption-of-the-budget-resolution',\n",
    "'physician-fee-freeze','el-salvador-aid','religious-groups-in-schools','anti-satellite-test-ban',\n",
    "'aid-to-nicaraguan-contras','mx-missle','immigration','synfuels-corporation-cutback','education-spending',\n",
    "'superfund-right-to-sue','crime','duty-free-exports','export-administration-act-south-africa']\n",
    "\n",
    "# Read data into CSV file and convert ? to NaN\n",
    "df = pd.read_csv(os.path.join(\"./house-votes-84.data.txt\")\n",
    "                       , names=COLUMNS\n",
    "                       , skipinitialspace=True\n",
    "                       , na_values=\"?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rows with NaN values are removed from data\n",
    "df.replace([\"NaN\"], np.nan, inplace = True)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "  \n",
    "#New row numbers after removing NaN values\n",
    "rows_number=df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label column republican/democrat to 1 and 0\n",
    "for i in range(0,len(COLUMNS)):\n",
    "    cleanup_nums = {COLUMNS[i]: {\"y\":1, \"n\":0, \"republican\":1,\"democrat\":0}}\n",
    "    df.replace(cleanup_nums, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      1\n",
      "8      0\n",
      "9      1\n",
      "10     0\n",
      "11     1\n",
      "12     0\n",
      "13     1\n",
      "14     1\n",
      "15     1\n",
      "16     0\n",
      "17     0\n",
      "18     0\n",
      "19     0\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     1\n",
      "24     1\n",
      "25     1\n",
      "26     1\n",
      "27     1\n",
      "28     0\n",
      "29     1\n",
      "      ..\n",
      "202    1\n",
      "203    0\n",
      "204    0\n",
      "205    0\n",
      "206    0\n",
      "207    1\n",
      "208    0\n",
      "209    0\n",
      "210    1\n",
      "211    1\n",
      "212    1\n",
      "213    0\n",
      "214    0\n",
      "215    1\n",
      "216    1\n",
      "217    0\n",
      "218    1\n",
      "219    0\n",
      "220    1\n",
      "221    0\n",
      "222    0\n",
      "223    0\n",
      "224    1\n",
      "225    0\n",
      "226    0\n",
      "227    0\n",
      "228    0\n",
      "229    1\n",
      "230    1\n",
      "231    0\n",
      "Name: className, Length: 232, dtype: int64\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Make a 2 column matrix for the labels column\n",
    "labels=np.zeros((rows_number, 2))\n",
    "label=df['className']\n",
    "print(label)\n",
    "for i in range(0,len(label)):\n",
    "    if(label[i]==0):\n",
    "        labels[i,0]=0\n",
    "        labels[i,1]=1\n",
    "    else:\n",
    "        labels[i,0]=1\n",
    "        labels[i,1]=0\n",
    "print (labels)\n",
    "inputs=df[COLUMNS[2:]]\n",
    "inputs=inputs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(inputs, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameters Training\n",
    "learning_rate = 0.5\n",
    "epochs = 50\n",
    "batch_size = 50 #small dataset\n",
    "\n",
    "n_features = 15\n",
    "n_calsses=2\n",
    "\n",
    "#HyperParameters NN\n",
    "hidden_nodes_layer1=10\n",
    "hidden_nodes_layer2=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define variables for weights and biases\n",
    "input_weights = tf.Variable(tf.random_normal([n_features, hidden_nodes_layer1]))\n",
    "input_biases = tf.Variable(tf.zeros([1,hidden_nodes_layer1]))\n",
    "\n",
    "hidden1_weights = tf.Variable(tf.random_normal([hidden_nodes_layer1, hidden_nodes_layer2]))\n",
    "hidden1_biases = tf.Variable(tf.zeros([1,hidden_nodes_layer2]))\n",
    "\n",
    "hidden2_weights = tf.Variable(tf.random_normal([hidden_nodes_layer2, n_calsses]))\n",
    "hidden2_biases = tf.Variable(tf.zeros([1,n_calsses]))\n",
    "\n",
    "weights={'input':input_weights,'hidden1':hidden1_weights,'hidden2':hidden2_weights}\n",
    "biases={'input':input_biases,'hidden1':hidden1_biases,'hidden2':hidden2_biases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholders to initialize \n",
    "x = tf.placeholder(tf.float32, [None, n_features])\n",
    "y = tf.placeholder(tf.float32, [None, n_calsses])\n",
    "\n",
    "#Create the NN model\n",
    "prediction=create_model(x,weights,biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', 1, 'cost=', 27.517919858296715)\n",
      "('Epoch:', 2, 'cost=', 0.7076063950856526)\n",
      "('Epoch:', 3, 'cost=', 0.7023968696594238)\n",
      "('Epoch:', 4, 'cost=', 0.6983156204223633)\n",
      "('Epoch:', 5, 'cost=', 0.6952630877494812)\n",
      "('Epoch:', 6, 'cost=', 0.6930194695790608)\n",
      "('Epoch:', 7, 'cost=', 0.6908019781112671)\n",
      "('Epoch:', 8, 'cost=', 0.6885601878166199)\n",
      "('Epoch:', 9, 'cost=', 0.6862834294637045)\n",
      "('Epoch:', 10, 'cost=', 0.6840344468752544)\n",
      "('Epoch:', 11, 'cost=', 0.681976060072581)\n",
      "('Epoch:', 12, 'cost=', 0.6787038048108419)\n",
      "('Epoch:', 13, 'cost=', 0.6744384169578552)\n",
      "('Epoch:', 14, 'cost=', 0.6699090202649435)\n",
      "('Epoch:', 15, 'cost=', 0.6668328245480855)\n",
      "('Epoch:', 16, 'cost=', 0.655076801776886)\n",
      "('Epoch:', 17, 'cost=', 0.6395849784215292)\n",
      "('Epoch:', 18, 'cost=', 0.6129528482755026)\n",
      "('Epoch:', 19, 'cost=', 0.5619836052258809)\n",
      "('Epoch:', 20, 'cost=', 0.4810996552308401)\n",
      "('Epoch:', 21, 'cost=', 0.4090161124865214)\n",
      "('Epoch:', 22, 'cost=', 0.3544098138809204)\n",
      "('Epoch:', 23, 'cost=', 0.3135599692662557)\n",
      "('Epoch:', 24, 'cost=', 0.2850495080153147)\n",
      "('Epoch:', 25, 'cost=', 0.25773461659749347)\n",
      "('Epoch:', 26, 'cost=', 0.2279452880223592)\n",
      "('Epoch:', 27, 'cost=', 0.20967992146809897)\n",
      "('Epoch:', 28, 'cost=', 0.19128817816575366)\n",
      "('Epoch:', 29, 'cost=', 0.1795717527468999)\n",
      "('Epoch:', 30, 'cost=', 0.16322636604309082)\n",
      "('Epoch:', 31, 'cost=', 0.15559141337871552)\n",
      "('Epoch:', 32, 'cost=', 0.15231983860333762)\n",
      "('Epoch:', 33, 'cost=', 0.14574847122033438)\n",
      "('Epoch:', 34, 'cost=', 0.13530891637007395)\n",
      "('Epoch:', 35, 'cost=', 0.13523440311352414)\n",
      "('Epoch:', 36, 'cost=', 0.1301730622847875)\n",
      "('Epoch:', 37, 'cost=', 0.12116249402364095)\n",
      "('Epoch:', 38, 'cost=', 0.12117191652456918)\n",
      "('Epoch:', 39, 'cost=', 0.11296761532624564)\n",
      "('Epoch:', 40, 'cost=', 0.11531415581703186)\n",
      "('Epoch:', 41, 'cost=', 0.10646820565064749)\n",
      "('Epoch:', 42, 'cost=', 0.10422000537316004)\n",
      "('Epoch:', 43, 'cost=', 0.10666006306807202)\n",
      "('Epoch:', 44, 'cost=', 0.09859194606542589)\n",
      "('Epoch:', 45, 'cost=', 0.09669895221789679)\n",
      "('Epoch:', 46, 'cost=', 0.1006345177690188)\n",
      "('Epoch:', 47, 'cost=', 0.09201359500487646)\n",
      "('Epoch:', 48, 'cost=', 0.0906547432144483)\n",
      "('Epoch:', 49, 'cost=', 0.08925807227691016)\n",
      "('Epoch:', 50, 'cost=', 0.09305800000826518)\n",
      "Accuracy: 0.98275864\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)    \n",
    "    #Training cycle\n",
    "    # Loop epochs\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0       \n",
    "        total_batch = int(len(x_train)/batch_size)\n",
    "        X_batches = np.array_split(x_train, total_batch)\n",
    "        Y_batches = np.array_split(y_train, total_batch)\n",
    "        # Loop batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "            # Run optimization and loss \n",
    "            _, cost = sess.run([optimizer, loss_function], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # average cost\n",
    "            avg_cost += cost / total_batch\n",
    "        print(\"Epoch:\", epoch+1, \"cost=\", avg_cost)\n",
    "    \n",
    "    #accuracy\n",
    "    print(\"Accuracy: \" + str(accuracy.eval(feed_dict={x: x_test,\n",
    "                                                          y: y_test})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
